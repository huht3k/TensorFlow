{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "references:\n",
    "https://www.tensorflow.org/get_started/tflearn\n",
    "https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/monitors/iris_monitors.py\n",
    "\n",
    "TensorFlow¡¯s high-level machine learning API (tf.contrib.learn) makes it easy to configure, train, and evaluate \n",
    "a variety of machine learning models. \n",
    "\n",
    "In this tutorial, you¡¯ll use tf.contrib.learn to construct a neural network classifier and train it \n",
    "on the Iris data set to predict flower species based on sepal/petal geometry. \n",
    "You'll write code to perform the following five steps:\n",
    "\n",
    "Load CSVs containing Iris training/test data into a TensorFlow Dataset\n",
    "Construct a neural network classifier\n",
    "Fit the model using the training data\n",
    "Evaluate the accuracy of the model\n",
    "Classify new samples\n",
    "\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import urllib\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ubuntu', '14.04', 'trusty')\n",
      "2.7.6\n",
      "1.0.1\n",
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please note, the environments for the codes.\n",
    "\"\"\"\n",
    "\n",
    "import platform\n",
    "\n",
    "print(platform.linux_distribution())\n",
    "\n",
    "print(platform.python_version())\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IRIS_TRAINING = \"./iris_data/iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"./iris_data/iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "\n",
    "# If the training and test sets aren't stored locally, download them.\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urllib.urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "        f.write(raw)\n",
    "\n",
    "if not os.path.exists(IRIS_TEST):\n",
    "    raw = urllib.urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"w\") as f:\n",
    "        f.write(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "[_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None)]\n"
     ]
    }
   ],
   "source": [
    "print(type(feature_columns))\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     120    4  setosa  versicolor  virginica\n",
      "0    6.4  2.8     5.6         2.2          2\n",
      "1    5.0  2.3     3.3         1.0          1\n",
      "2    4.9  2.5     4.5         1.7          2\n",
      "3    4.9  3.1     1.5         0.1          0\n",
      "4    5.7  3.8     1.7         0.3          0\n",
      "5    4.4  3.2     1.3         0.2          0\n",
      "6    5.4  3.4     1.5         0.4          0\n",
      "7    6.9  3.1     5.1         2.3          2\n",
      "8    6.7  3.1     4.4         1.4          1\n",
      "9    5.1  3.7     1.5         0.4          0\n",
      "10   5.2  2.7     3.9         1.4          1\n",
      "11   6.9  3.1     4.9         1.5          1\n",
      "12   5.8  4.0     1.2         0.2          0\n",
      "13   5.4  3.9     1.7         0.4          0\n",
      "14   7.7  3.8     6.7         2.2          2\n",
      "15   6.3  3.3     4.7         1.6          1\n",
      "16   6.8  3.2     5.9         2.3          2\n",
      "17   7.6  3.0     6.6         2.1          2\n",
      "18   6.4  3.2     5.3         2.3          2\n",
      "19   5.7  4.4     1.5         0.4          0\n",
      "20   6.7  3.3     5.7         2.1          2\n",
      "21   6.4  2.8     5.6         2.1          2\n",
      "22   5.4  3.9     1.3         0.4          0\n",
      "23   6.1  2.6     5.6         1.4          2\n",
      "24   7.2  3.0     5.8         1.6          2\n",
      "25   5.2  3.5     1.5         0.2          0\n",
      "26   5.8  2.6     4.0         1.2          1\n",
      "27   5.9  3.0     5.1         1.8          2\n",
      "28   5.4  3.0     4.5         1.5          1\n",
      "29   6.7  3.0     5.0         1.7          1\n",
      "..   ...  ...     ...         ...        ...\n",
      "90   6.5  3.0     5.2         2.0          2\n",
      "91   6.1  2.8     4.7         1.2          1\n",
      "92   5.1  3.5     1.4         0.3          0\n",
      "93   4.6  3.1     1.5         0.2          0\n",
      "94   6.5  3.0     5.8         2.2          2\n",
      "95   4.6  3.4     1.4         0.3          0\n",
      "96   4.6  3.2     1.4         0.2          0\n",
      "97   7.7  2.8     6.7         2.0          2\n",
      "98   5.9  3.2     4.8         1.8          1\n",
      "99   5.1  3.8     1.6         0.2          0\n",
      "100  4.9  3.0     1.4         0.2          0\n",
      "101  4.9  2.4     3.3         1.0          1\n",
      "102  4.5  2.3     1.3         0.3          0\n",
      "103  5.8  2.7     4.1         1.0          1\n",
      "104  5.0  3.4     1.6         0.4          0\n",
      "105  5.2  3.4     1.4         0.2          0\n",
      "106  5.3  3.7     1.5         0.2          0\n",
      "107  5.0  3.6     1.4         0.2          0\n",
      "108  5.6  2.9     3.6         1.3          1\n",
      "109  4.8  3.1     1.6         0.2          0\n",
      "110  6.3  2.7     4.9         1.8          2\n",
      "111  5.7  2.8     4.1         1.3          1\n",
      "112  5.0  3.0     1.6         0.2          0\n",
      "113  6.3  3.3     6.0         2.5          2\n",
      "114  5.0  3.5     1.6         0.6          0\n",
      "115  5.5  2.6     4.4         1.2          1\n",
      "116  5.7  3.0     4.2         1.2          1\n",
      "117  4.4  2.9     1.4         0.2          0\n",
      "118  4.8  3.0     1.4         0.1          0\n",
      "119  5.5  2.4     3.7         1.0          1\n",
      "\n",
      "[120 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(IRIS_TRAINING)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    }
   ],
   "source": [
    "validation_metrics = {\n",
    "      \"accuracy\":\n",
    "          tf.contrib.learn.MetricSpec(\n",
    "              metric_fn=tf.contrib.metrics.streaming_accuracy,\n",
    "              prediction_key=\"classes\"),\n",
    "      \"precision\":\n",
    "          tf.contrib.learn.MetricSpec(\n",
    "              metric_fn=tf.contrib.metrics.streaming_precision,\n",
    "              prediction_key=\"classes\"),\n",
    "      \"recall\":\n",
    "          tf.contrib.learn.MetricSpec(\n",
    "              metric_fn=tf.contrib.metrics.streaming_recall,\n",
    "              prediction_key=\"classes\")\n",
    "  }\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "      test_set.data,\n",
    "      test_set.target,\n",
    "      every_n_steps=50,\n",
    "      metrics=validation_metrics,\n",
    "      early_stopping_metric=\"loss\",\n",
    "      early_stopping_metric_minimize=True,\n",
    "      early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 1, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4049e077d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                              hidden_units=[10, 20, 10],\n",
    "                                              n_classes=3,\n",
    "                                              model_dir=\"./iris_model\",\n",
    "                                              config = tf.contrib.learn.RunConfig(save_checkpoints_secs = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-876735c5fa9c>:6: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-23-876735c5fa9c>:6: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 4302 into ./iris_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.029218, step = 4302\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:657: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:657: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-30-08:53:34\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-30-08:53:35\n",
      "INFO:tensorflow:Saving dict for global step 4302: accuracy = 0.966667, auc = 0.998333, global_step = 4302, loss = 0.102701, precision = 1.0, recall = 1.0\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "INFO:tensorflow:Validation (step 4351): loss = 0.102701, auc = 0.998333, global_step = 4302, recall = 1.0, precision = 1.0, accuracy = 0.966667\n",
      "INFO:tensorflow:Stopping. Best step: 4051 with loss = 0.0972830876708.\n",
      "INFO:tensorflow:Saving checkpoints for 4351 into ./iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0293075.\n",
      "WARNING:tensorflow:From <ipython-input-23-876735c5fa9c>:10: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-23-876735c5fa9c>:10: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-30-08:53:35\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-30-08:53:36\n",
      "INFO:tensorflow:Saving dict for global step 4351: accuracy = 0.966667, auc = 0.998333, global_step = 4351, loss = 0.129907\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "Accuracy: 0.966667\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Fit model.\n",
    "classifier.fit(x=training_set.data,\n",
    "                   y=training_set.target,\n",
    "                   steps=2000,\n",
    "                   monitors=[validation_monitor])\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(x=test_set.data,\n",
    "                                         y=test_set.target)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:374: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "Predictions: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Classify two new flower samples.\n",
    "new_samples = np.array(\n",
    "        [[6.4, 3.2, 4.5, 1.5], [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
    "\n",
    "y = list(classifier.predict(new_samples, as_iterable=True))\n",
    "print('Predictions: {}'.format(str(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
